{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knowledge_graph.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKWKk5Gy+x08nVPKsVhej4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loftusa/linear_sum_assignment/blob/main/knowledge_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic updating algorithm\n",
        "\n",
        "$\\hat{P}_{b,l}^{(i)} = (1-\\epsilon)\\frac{\\sum_{b', b' \\neq b} \\sum_{l'} S_{l, l'} \\hat{P}_{b', l'}^{(i-1)}}{\\sum_{b', b' \\neq b} \\sum_{l'} S_{l, l'}} + \\epsilon P_{b,l}$\n",
        "\n",
        "Can initialize arbitrarilty, so we'll just use the prior $P_{b,l}$\n",
        "\n",
        "Initalization value is $\\frac{1}{nlabels}$"
      ],
      "metadata": {
        "id": "njQWp5lGh_t7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oczzE0dgTsG",
        "outputId": "6cc4bf72-bec7-4cf4-e876-9ad0500a6f37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 0.7 , 0.2 ],\n",
              "       [0.7 , 1.  , 0.15],\n",
              "       [0.2 , 0.15, 1.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# fork, spoon, monkey\n",
        "# first bounding box has a fork\n",
        "# second bounding box has a spoon\n",
        "# goal: P_hat should end up having a higher value\n",
        "# for the argmax of each row, and a lower value for the rest.\n",
        "P = np.array([[.7, .6, .4],\n",
        "              [.6, .9, .5]])\n",
        "\n",
        "# S: fork, spoon, monkey\n",
        "S = np.array([[.5, .7, .2],\n",
        "              [0,  .5, .15],\n",
        "              [0, 0, .5]])\n",
        "S = S + S.T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cpu\"\n",
        "e = .5\n",
        "b, l = 0, 0\n",
        "nb, nl = P.shape  # num bounding boxes, num labels\n",
        "\n",
        "numerator = 0\n",
        "denominator = 0\n",
        "for b_ in range(nb):\n",
        "  if b_ != b:\n",
        "    for l_ in range(nl):\n",
        "      numerator += (S[l, l_] * P[b_, l_])\n",
        "      denominator += S[l, l_]"
      ],
      "metadata": {
        "id": "031b50G5xfRq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rbYlmPIXQBOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y5A4FZ2QpJy",
        "outputId": "c33cf508-50fe-4b03-97af-42e4be1a8dff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.03"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3VHfBBRQqDx",
        "outputId": "c6c33423-1ec2-4912-da8c-29bc3751d428"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S @ P.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gv1xYUPQX7P",
        "outputId": "d44b0b10-b517-4491-ba89-9c8abc5f1a8e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8500, 1.0300],\n",
              "        [0.3600, 0.5250],\n",
              "        [0.2000, 0.2500]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(S, torch.transpose(P, 0, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amOdJa-oQaZP",
        "outputId": "f318e60d-90a0-4cfb-90f9-587f2bf3471a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8500, 1.0300],\n",
              "        [0.3600, 0.5250],\n",
              "        [0.2000, 0.2500]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P_hat = torch.full(size=P.shape, fill_value=(1/nl), dtype=torch.double).to(device)\n",
        "if not isinstance(P, torch.Tensor):\n",
        "  P = torch.from_numpy(P).to(device)\n",
        "if not isinstance(S, torch.Tensor):\n",
        "  S = torch.from_numpy(S).to(device)\n",
        "  \n",
        "torch.sum(torch.mm(S, torch.transpose(P, 0, 1)), 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaMFyeALEHH3",
        "outputId": "53cff8b7-fe4e-49d8-c05e-3c000899dcea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.8800, 0.8850, 0.4500], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(torch.mm(S, P_hat))"
      ],
      "metadata": {
        "id": "OPZFU4xtEvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"gpu\"\n",
        "e = .5\n",
        "b, l = 0, 0\n",
        "num_boxes, num_classes = P.shape  # num bounding boxes, num labels\n",
        "numerator = 0\n",
        "denominator = 0\n",
        "num_iterations = 10\n",
        "\n",
        "p_hat_init = torch.full(size=(num_boxes, num_classes), fill_value=(1 / num_classes), dtype=torch.double).to(device)\n",
        "p_hat = p_hat_init\n",
        "for i in range(num_iterations):\n",
        "    p_hat_temp = torch.clone(p_hat)\n",
        "    for b in range(num_boxes):\n",
        "        p = predictions[b]\n",
        "        num = torch.sum(torch.mm(S_highest, torch.transpose(p_hat_temp[box_nearest[b]], 0, 1)), 1)\n",
        "        denom = torch.sum(S_highest, dim=1) * bk\n",
        "        p_hat[b] = (1 - epsilon) * torch.squeeze(torch.div(num, denom)) + epsilon * p\n",
        "        p_hat[b] = torch.nan_to_num(p_hat[b])\n",
        "\n",
        "return p_hat"
      ],
      "metadata": {
        "id": "cmFOxwWdxO6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"gpu\"\n",
        "e = .5\n",
        "b, l = 0, 0\n",
        "nb, nl = P.shape  # num bounding boxes, num labels\n",
        "numerator = 0\n",
        "denominator = 0\n",
        "\n",
        "for b_ in range(nb):\n",
        "  if b_ != b:\n",
        "    for l_ in range(nl):\n",
        "      numerator += (S[l, l_] * P[b_, l_])\n",
        "      denominator += S[l, l_]\n",
        "\n",
        "def find_p_hat(boxes, predictions, bk, lk, S, num_iterations, epsilon):\n",
        "    \"\"\"\n",
        "    Compute the knowledge aware predictions, based on the object detector's output and semantic consistency.\n",
        "    :param boxes: tensor of bounding boxes\n",
        "    :param predictions: tensor of prediction scores\n",
        "    :param bk: number of neighbouring bounding boxes to consider for p_hat\n",
        "    :param lk: number of largest semantic consistent classes to consider for p_hat\n",
        "    :param S: semantic consistency matrix\n",
        "    :param num_iterations: number of iterations to calculate p_hat\n",
        "    :param epsilon: trade-off parameter for traditional detections and knowledge aware detections\n",
        "    :return p_hat: tensor of knowledge aware predictions\n",
        "    \"\"\"\n",
        "\n",
        "    num_boxes = predictions.shape[0]\n",
        "    num_classes = predictions.shape[1]\n",
        "\n",
        "    if num_boxes <= 1:\n",
        "        return predictions\n",
        "\n",
        "    if num_boxes <= bk:\n",
        "        bk = num_boxes - 1\n",
        "\n",
        "    if num_classes <= lk:\n",
        "        lk = num_classes\n",
        "\n",
        "    box_centers = torch.empty(size=(num_boxes, 2), dtype=torch.double).to(device)\n",
        "    box_centers[:, 0] = ((boxes[:, 2] - boxes[:, 0]) / 2) + boxes[:, 0]\n",
        "    box_centers[:, 1] = ((boxes[:, 3] - boxes[:, 1]) / 2) + boxes[:, 1]\n",
        "\n",
        "    box_nearest = torch.empty(size=(num_boxes, bk), dtype=torch.long).to(device)\n",
        "    for i in range(len(boxes)):\n",
        "        box_center = box_centers[i]\n",
        "        distances = torch.sqrt((box_center[0] - box_centers[:, 0]) ** 2 + (box_center[1] - box_centers[:, 1]) ** 2)\n",
        "        distances[i] = float('inf')\n",
        "        box_nearest[i] = torch.argsort(distances)[0:bk]\n",
        "\n",
        "    S_highest = torch.zeros(size=(num_classes, num_classes), dtype=torch.double).to(device)\n",
        "    for i in range(len(S)):\n",
        "        S_args = torch.argsort(S[i])[-lk:]\n",
        "        S_highest[i, S_args] = S[i, S_args]\n",
        "\n",
        "    p_hat_init = torch.full(size=(num_boxes, num_classes), fill_value=(1 / num_classes), dtype=torch.double).to(device)\n",
        "    p_hat = p_hat_init\n",
        "    for i in range(num_iterations):\n",
        "        p_hat_temp = torch.clone(p_hat)\n",
        "        for b in range(num_boxes):\n",
        "            p = predictions[b]\n",
        "            num = torch.sum(torch.mm(S_highest, torch.transpose(p_hat_temp[box_nearest[b]], 0, 1)), 1)\n",
        "            denom = torch.sum(S_highest, dim=1) * bk\n",
        "            p_hat[b] = (1 - epsilon) * torch.squeeze(torch.div(num, denom)) + epsilon * p\n",
        "            p_hat[b] = torch.nan_to_num(p_hat[b])\n",
        "\n",
        "    return p_hat"
      ],
      "metadata": {
        "id": "dPyZftM8gZYd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tmi1jXeJoJ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "numerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9aT7-vfmRUk",
        "outputId": "26843252-918f-4fb2-a836-6fd38a255304"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.03"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCN6AnfmR5C",
        "outputId": "3f17ecb6-985b-4b9a-dcc0-c679509d569b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}